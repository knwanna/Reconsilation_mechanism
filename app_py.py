# -*- coding: utf-8 -*-
"""Basic Data Reconciliation Service (app.py)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15V7XxZ1yVjIIBz2elNeewtoMcirOEgGo
"""

# app.py
from flask import Flask, request, jsonify
import pandas as pd
import os
import logging

# Configure basic logging to show messages in the console
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

app = Flask(__name__)

# --- Configuration ---
# Construct the absolute path to the data file.
# This ensures the application can find the CSV file regardless of the current working directory.
DATA_FILE_PATH = os.path.join(os.path.dirname(__file__), 'data', 'literary_works.csv')

# Global variable to hold our loaded dataset.
# It's populated once when the application starts.
_dataset = []

# --- Data Loading Function ---
def load_dataset():
    """
    Loads the dataset from the CSV file into memory.
    This function is executed once when the Flask application initializes.
    Includes basic error handling for file operations.
    """
    global _dataset
    try:
        logging.info(f"Attempting to load dataset from: {DATA_FILE_PATH}")
        # Use pandas to read the CSV file, which handles common CSV quirks robustly.
        df = pd.read_csv(DATA_FILE_PATH)
        # Convert the pandas DataFrame to a list of dictionaries, which is easy to iterate.
        _dataset = df.to_dict(orient='records')
        logging.info(f"Successfully loaded {len(_dataset)} records from {DATA_FILE_PATH}")
    except FileNotFoundError:
        logging.error(f"Dataset file not found: {DATA_FILE_PATH}. Please ensure it exists in the 'data' folder.")
        _dataset = [] # Ensure dataset is empty if the file isn't found
    except pd.errors.EmptyDataError:
        logging.error(f"Dataset file is empty: {DATA_FILE_PATH}. Please ensure it contains data.")
        _dataset = []
    except Exception as e:
        # Catch any other unexpected errors during file loading or parsing.
        logging.error(f"An unexpected error occurred while loading dataset from {DATA_FILE_PATH}: {e}")
        _dataset = []

# --- Initial Data Load on Application Startup ---
# This block ensures that load_dataset() is called when the Flask app starts.
# app.app_context() is used to ensure Flask's logging and other features are available during startup.
with app.app_context():
    load_dataset()

# --- API Endpoints ---

@app.route('/')
def home():
    """
    Defines the home endpoint for the API.
    This provides a simple welcome message, useful for a quick check that the service is running.
    """
    return "Welcome to the Basic Reconciliation Service. Use the /reconcile endpoint with a 'query' parameter."

@app.route('/reconcile', methods=['GET'])
def reconcile():
    """
    Implements the core reconciliation API endpoint.

    This endpoint accepts a single query string parameter named 'query'.
    It searches the loaded dataset for items whose 'name' attribute matches the query
    based on defined rules (exact, starts-with, partial substring match).

    Query Parameters:
        query (str): The text string to reconcile (e.g., "George Orwell", "1984").
                     This parameter is mandatory.

    Returns:
        JSON: A list of dictionaries, where each dictionary represents a potential match.
              Each match object includes:
              - 'id': The unique identifier of the matched item.
              - 'name': The display name of the matched item.
              - 'score': A float (0.0 to 1.0) indicating match confidence (1.0 for exact).
              - 'match_type': A descriptive string (e.g., "exact_match").

              Returns an empty JSON list ([]) if no matches are found.
              Returns a 400 Bad Request if 'query' parameter is missing.
              Returns a 500 Internal Server Error if the dataset isn't loaded correctly.
    """
    # Get the 'query' parameter from the request URL. Default to an empty string if not present.
    search_query = request.args.get('query')

    # --- Input Validation ---
    if not search_query:
        logging.warning("Reconciliation request received with missing 'query' parameter. Returning 400.")
        return jsonify({"error": "Missing 'query' parameter. Please provide a string to reconcile."}), 400

    # --- Dataset Availability Check ---
    # Ensures that the service can actually perform the search.
    if not _dataset:
        logging.error("Attempted reconciliation with an empty dataset. This likely means data loading failed.")
        return jsonify({"error": "Service dataset is not available. Please contact administrator."}), 500

    results = [] # List to store all found matches

    # Normalize the search query once for efficient, case-insensitive comparison.
    lower_search_query = search_query.strip().lower()

    # --- Iterate and Match ---
    for item in _dataset:
        item_id = item.get('id')
        item_name = item.get('name')

        # Skip items that do not have a 'name' attribute, as it's essential for matching.
        if item_name is None:
            logging.debug(f"Skipping item with ID {item_id} due to missing 'name' attribute.")
            continue

        # Normalize the item's name from the dataset for comparison.
        lower_item_name = str(item_name).lower()

        score = 0.0 # Default score, indicates no match initially
        match_type = "no_match" # Default match type

        # --- Rule-Based Matching Logic (Hierarchical) ---
        # 1. Exact Match: Highest confidence.
        if lower_search_query == lower_item_name:
            score = 1.0
            match_type = "exact_match"
        # 2. Starts-With Match: High confidence, query is a prefix of the item's name.
        elif lower_item_name.startswith(lower_search_query):
            score = 0.9
            match_type = "starts_with_match"
        # 3. Partial Substring Match: Medium confidence, query is found anywhere within the item's name.
        elif lower_search_query in lower_item_name:
            score = 0.8
            match_type = "partial_substring_match"

        # If a match was found (score > 0), add it to the results list.
        if score > 0:
            results.append({
                "id": item_id,
                "name": item_name,
                "score": score,
                "match_type": match_type # Custom field for clarity in output
            })

    # --- Sort Results ---
    # Sort the results by score in descending order to present the best matches first.
    results.sort(key=lambda x: x['score'], reverse=True)

    logging.info(f"Reconciled query '{search_query}'. Found {len(results)} potential matches.")
    # Return the results as a JSON response.
    return jsonify(results)

# --- Application Entry Point ---
if __name__ == '__main__':
    # This block executes when the script is run directly.
    # app.run() starts the Flask development server.
    # debug=True: Enables debug mode, providing automatic reloader and debugger.
    #            DO NOT use in production.
    # host='127.0.0.1': Binds the server to localhost, making it accessible only from your machine.
    # port=5000: Specifies the port number the server will listen on.
    app.run(debug=True, host='127.0.0.1', port=5000)